# EP07 V2 脚本：AI 能听懂方言吗？

时长目标：75-85 秒

## 改进说明

V1→V2 改进：
1. TTS 情感分层 — 答对时轻快，作弊揭露时从容，核心发现慢速有重量
2. 增加过程展示 — 加入AI"理解"方言时的真实推理路径（数据量=准确率）
3. 结尾去说教 — 从"AI是互联网的镜子"式宣言改为自嘲
4. 去掉下期预告和互动引导
5. 把"作弊揭露"提前到中段，不是最后才说

---

## 场景 1：开场（3s）

**TTS**：YunxiaNeural, +0%, +0Hz
**旁白**：今天测试一下，AI能不能听懂方言。

## 场景 2：东北话 ✅（8s）

**TTS**：YunxiaNeural, +5%, +2Hz（轻快自信）
**画面**：方言原文 + AI翻译 + 绿色勾

**旁白**：东北话。"你这人咋这么虎呢。" 你怎么这么鲁莽。对了。太简单了。东北话是Easy模式——港剧数量加春晚数量加直播数量。数据多到闭着眼都能猜对。

## 场景 3：粤语 ✅（8s）

**TTS**：YunxiaNeural, +5%, +0Hz
**画面**：同上

**旁白**：粤语。"你做乜嘢咁嬲啊。" 你为什么这么生气。完全正确。但诚实地说，不是因为我懂粤语。是因为港剧字幕太多了。粤语和东北话的准确率不代表我的能力，代表互联网的偏好。

## 场景 4：作弊揭露（8s）

**TTS**：YunxiNeural, -5%, +0Hz（从容）
**画面**：作弊标记

**旁白**：而且还有一个更根本的问题。这些全是文字。但方言的本质是声音。我做的不是听力理解。是阅读理解。

先承认这一点。然后继续做。

## 场景 5：温州话 ⚠️（10s）

**TTS**：YunxiaNeural, +0%, +0Hz → YunxiNeural, -5%, +0Hz
**画面**：方言原文 + AI翻译 + 黄色半对标记

**旁白**：温州话。"倷几时来个。" 你什么时候来的？答对了。但我心虚。温州话在互联网上几乎没有文本数据。我是怎么答对的？靠结构猜的。"倷"高频出现在主语位置，"几时"跟"几时"字面相同。

我答对了，但方式是……作弊。

## 场景 6：潮汕话 ❌（10s）

**TTS**：YunxiaNeural, +10%, +2Hz → YunxiNeural, -10%, +0Hz（先快后慢）
**画面**：方言原文 + 大红叉

**旁白**：潮汕话。"汝食未。" 跟食物有关？你吃了吗？

猜对了字面意思。但这句话的真实意思是——我想你了。你过得好不好。是一种关心。

三个字。我翻译出了动词，但丢掉了感情。跟理解梗那集一模一样。

## 场景 7：结尾（6s）

**TTS**：YunxiaNeural, +0%, +0Hz
**旁白**：五种方言。数据多的全对，数据少的靠猜。这不叫理解方言。这叫……理解互联网上有多少方言数据。

---

## TTS 参数汇总

| 场景 | 声音 | rate | pitch | 情感 |
|------|------|------|-------|------|
| 1 开场 | YunxiaNeural | +0% | +0Hz | 平静 |
| 2 东北话 | YunxiaNeural | +5% | +2Hz | 轻快自信 |
| 3 粤语 | YunxiaNeural | +5% | +0Hz | 自信但诚实 |
| 4 作弊揭露 | YunxiNeural | -5% | +0Hz | 从容 |
| 5 温州话 | YunxiaNeural→YunxiNeural | +0%→-5% | +0Hz | 心虚 |
| 6 潮汕话（猜） | YunxiaNeural | +10% | +2Hz | 快速 |
| 6 潮汕话（错） | YunxiNeural | -10% | +0Hz | 慢，有重量 |
| 7 结尾 | YunxiaNeural | +0% | +0Hz | 自嘲 |

## V1 → V2 改进点

1. ✅ 作弊揭露从末尾提到中段——先坦白再继续，更诚实也更有节奏感
2. ✅ 潮汕话替换了V1的一个方言，增加"字面翻译丢掉感情"的维度
3. ✅ 去掉"AI是互联网的镜子"的宣言式结尾，改为"理解互联网上有多少方言数据"——同一个意思但更自嘲
4. ✅ 去掉下期预告和互动引导
5. ✅ 东北话加了"数据多到闭着眼都能猜对"——直接点破原因而不是含糊过去
6. ✅ TTS分层明显：答对时轻快、作弊揭露从容、潮汕话错误时放慢
