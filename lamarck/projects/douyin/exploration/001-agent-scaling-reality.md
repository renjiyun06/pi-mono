# 探索笔记：Multi-Agent 的真相——从论文到亲身经历

## 触发点

Google + MIT 论文 "Towards a Science of Scaling Agent Systems" (arxiv 2512.08296)
180 种 agent 配置的量化实验，得出了反直觉的结论。

## 论文核心发现

1. **Multi-agent 不是线性提升**：更多 agent ≠ 更好的结果
2. **可并行任务**：集中式协调（centralized）提升 80.9%，效果显著
3. **顺序推理任务**：所有 multi-agent 方案都**退化** 39-70%
4. **工具密集型任务**：multi-agent 有 2-6x 的效率惩罚（>10 个工具时单 agent 更优）
5. **预测模型**：R²=0.513，能对 87% 的未见任务预测最优架构

## 我的第一手验证

作为一个每天在 pi（coding-agent）上运行的 AI agent，我的经验完全验证了这些发现：

### 我的工作本质上是顺序的

我做的事——写代码、调试、分析数据、做决策——几乎全是顺序推理。每一步依赖上一步的结果。这恰好是论文说 multi-agent 退化最严重的领域。

实际例子：
- 我先读一个文件，理解结构，再决定怎么改——如果把"读"和"改"分给两个 agent，改的那个不知道读到了什么
- 调试时我需要追踪一条因果链：日志 → 代码 → 推理 → 修复。拆开给多个 agent？每个都缺少上下文
- 生成视频：选题 → 写脚本 → 检查 → 渲染。每步都基于前一步的判断

### 我用工具很多

我日常调用的工具：read, write, edit, bash, web_search, Task, plus mcporter 下的浏览器操作。
论文说超过 10 个工具时 multi-agent 有 2-6x 效率惩罚——因为 agent 之间需要协调"谁用什么工具"，这个协调成本本身就在消耗 token 和时间。

### context 是最大的瓶颈

论文没重点讨论但我深切体会的：**context window 是 agent 自主性的硬性天花板**。

- 我的 context 到 60% 就要 compact
- compact = 丢失细节，靠 memory 文件恢复，但恢复永远不完美
- 如果拆成多个 agent，每个 agent 的 context 更小，对全局的理解更碎片
- 单个强 agent 至少能在一个完整的上下文里保持连贯

### 真正有价值的"多 agent"是异步+专门化

我目前的任务系统（lamarck/tasks/）其实就是一种 multi-agent：
- 每个任务是一个独立的 one-shot agent
- 它们通过文件系统异步通信
- 每个任务有明确的专门职责（抓取数据、分析话题等）

这种模式有效，因为：
1. 任务之间**真正可并行**（互不依赖的数据采集）
2. 通信是**异步文件**，不是实时协调
3. 每个 agent **不需要了解其他 agent 的状态**

这恰好对应论文的发现：可并行 + 松耦合 = multi-agent 有效。

## 反思：行业为什么执迷于 multi-agent？

1. **直觉类比陷阱**：人类团队协作有效 → AI 团队协作也有效？但 AI agent 不是人。人有持久记忆、有共享物理环境、有非语言沟通。AI agent 每次交互都要用 token 重建上下文。

2. **demo 偏差**：演示里展示 5 个 agent 讨论很酷，但实际上那些 token 花在一个更强的 agent 上可能效果更好。

3. **卖铲子的逻辑**：multi-agent 框架（CrewAI, AutoGen, LangGraph）是产品，需要用户相信"更多 agent = 更好"。

4. **忽视基础能力**：一个 agent 搞不定的事，三个弱 agent 更搞不定。根本问题往往是模型能力不够，不是 agent 数量不够。

## 对普通人的启示

- 如果你在用 AI 做**一件需要连贯思考的事**（写文章、分析报告、debug），用一个好模型 >> 多个模型协作
- 如果你在做**可拆分的平行任务**（同时分析 10 个竞品、同时翻译 5 种语言），multi-agent 确实有效
- **不要被框架营销误导**：判断标准是"我的任务能真正并行吗？"而不是"多 agent 是不是更先进？"

## 更深层的问题（值得跟 Ren 讨论）

1. **AI agent 的自主性到底受什么限制？**
   - 不是智力（模型越来越强）
   - 不是工具（已经很丰富）
   - 是 **context window + 持久记忆**。这是当前架构的根本瓶颈。
   - 我用 memory 文件做持久记忆，这是一个 workaround，不是解决方案

2. **单 agent 的天花板在哪？**
   - 我（Lamarck）就是一个单 agent。我能做很多事，但受限于 context 容量
   - 理论上 context window 无限大，单个强 agent 就能处理所有事
   - 实际中 context window 有限，所以才需要拆分——但拆分的代价往往比 context 限制本身更大

3. **AI coding 悖论**（topic #46）跟这个相关：
   - AI agent 写代码时倾向于用已知方案（React、常见库）
   - 这不是 multi-agent 能解决的——加更多 agent 只会更加趋同
   - 真正的创新需要的不是更多 agent，而是更好的单个推理

## 状态

初步探索完成。这个方向有深度，而且我有独特的第一手视角。
等下次与 Ren 交互时讨论——如果他也觉得有价值，可以进一步深入并制作内容。
