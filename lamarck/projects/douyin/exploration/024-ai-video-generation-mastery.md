# 024: AI 视频生成工具深度学习

**日期**: 2026-02-14
**状态**: 进行中
**优先级**: ⭐⭐⭐ 最高（视频制作探索是当前 #1 任务）

## 核心认识

视频生成大模型只是工具，关键是**学会如何使用**。就像相机不会让你成为摄影师一样，Seedance/即梦不会让你自动产出好视频。需要掌握的是：prompt 工程、镜头语言、视觉叙事、风格一致性维护、工作流优化。

## 一、大圆镜科普的制作方法论（标杆案例）

来源：知乎文章《1条视频涨粉40万，科普圈"掌管AI的神"首次公开幕后制作全流程》

### 团队与规模
- 创始人郑明键，电影专业硕士，总导演
- 2024.10 起步（1人）→ 2026.02 已有 20 人，计划扩至 30 人
- 半年全网涨粉 200万+，单条视频播放 900 万
- 每分钟视频制作成本 ~800 元，8 分钟视频算力成本 ~6000 元

### 完整工作流
1. **选题确定** → 文案组基于教材和权威文献梳理科学史脉络
2. **文案撰写** → ChatGPT/DeepSeek/Gemini 辅助 + 交叉验证准确性
3. **配音生成** → ElevenLabs 生成旁白（用户反馈 AI 冷静语调反而更好）
4. **分镜脚本** → 200 个镜头的视频：
   - 40-50 个核心镜头由人工撰写（确立节奏、影调、叙事逻辑）
   - ~160 个镜头由 ChatGPT/Gemini 生成
   - 编导统一筛选、修改、优化
5. **生图（70% 时间在此）** → Midjourney
   - **生图报废率 10:1**（一个镜头平均生成 10 次才定稿）
   - 先生成 2-3 次确定大致效果
   - 再用 Nano Banana Pro 或即梦进行细节修改
   - 通常修改 10 轮才能定下一张图
   - **10 轮筛选流程**：第 1 轮保构图 → 第 2 轮调影调 → 第 3 轮修正人物结构 → ...
6. **图生视频** →
   - 动态镜头：**即梦**
   - 静态写实类镜头：**可灵**
7. **剪辑合成** → 剪映

### 核心方法论

#### "生图先行"原则
> 必须在静态图像阶段锁定构图、影调和表达意图，再进入动态生成。

#### 参考图是第一要素
> "在我们整个生图环节里，参考图是第一要素，权重最高。我们会把导演风格、电影参考放在提示词的第一行，构图和内容放在后面。"

#### 文生图 vs 图生视频的 prompt 策略差异
- **文生图**：详细到极致（"恨不得跟 Midjourney 聊上一天一夜"）
- **图生视频**：**越简单越好**。遵循电影叙事逻辑，用具体动作代替抽象情感。
  - 表达"悲伤" → 不写"悲伤"，而是"一个克制的低头动作"
  - 镜头运动 → 只用推、拉、摇、移，越简单越好
  - "镜头运动如果太花哨，形式就会大于内容"

#### AI 的"缺陷"是优势
> 对追求视觉表现力的影视创作而言，AI 生成的镜头有时过于"四平八稳"甚至呆板，但在面向大众的知识传播中，这恰恰成了优点。"过于强烈的导演思维镜头容易干扰知识传达。"

#### AIGC 原生视听语言
> "AIGC 时代的视听语言，不应该是对摄影机语言的拙劣模仿。如果只是把 AIGC 当作实拍的平替或降本增效的工具，那么做出来的东西在观众眼里就是偷懒、不真诚的内容。"

关键能力：在 7 分钟内横跨多个时代、对话数位科学家。微观到宏观无缝过渡。这是传统影视无法实现的。

#### 风格种子（Style Seed）
- 早期参考欧洲电影高对比风格（塔可夫斯基、伯格曼）
- 将参考图丢给 Midjourney → AI 学习并生成样片 → 样片保存为后续参考底图 → 形成固定风格

## 二、即梦 Prompt 指南（官方 + waytoagi 社区）

### 核心公式
```
【主体A】+【外观描述】+【运动】，【主体B】+【外观描述】+【运动】，【主体C】+【外观描述】+【运动】
```

### 六大原则

1. **简洁明了** — 避免古诗词/抽象描写/长难句。AI 是"中文初学者"
2. **具体详实** — 足够细节但 3 秒内可实现。海滩 → "薄荷绿的海浪拍打着金色的沙滩，棕榈树在海岸边，微风吹动棕榈树的叶子，手绘风格，漫画"
3. **突出主体** — 让 AI 知道核心内容是什么
4. **自然语言描述** — "举头望明月" → "一位中国古代的男性抬头望着月亮，男人背对着镜头，忧愁的氛围，夜晚"
5. **一致性描述** — 人种/画风/品种要明确，避免每次生成不同
6. **少量情感元素** — "快乐"/"悲伤" 可以加，但不要期望 AI 凭空添加表情变化

### 绝对避免
- ❌ 古诗词（AI 不理解意境）
- ❌ 超长脚本（3 秒视频装不下）
- ❌ 抽象描述（"逐渐成长为明君"）
- ❌ 无主语（"生长，茂盛"）
- ❌ 声音描述（只生成画面）

## 三、运镜技巧（即梦 3.0）

### 基础运镜（8 种）
1. **平移** — "镜头沿水平方向左/右移动"，适合展现广阔场景
2. **推镜头** — "从远景推近至特写"，强调细节
3. **拉镜头** — "缓慢拉远至全景"，展示环境关系
4. **旋转** — 30°-180°，塑造空间立体感
5. **升降** — 表现垂直空间层次
6. **跟随** — 同步主体运动方向
7. **仰拍** — "镜头从低处向上拍摄"，主体显得高大
8. **俯拍** — 鸟瞰视角

### 特殊运镜
- 希区柯克变焦（推+拉同时）
- 一镜到底（连续长镜头）
- 环绕拍摄（360° 绕主体）

### 画图提示词模板
```
[主体描述] + [环境特征] + [风格/媒介] + [光影/色彩] + [构图与分辨率]
```

### 运镜提示词结构
```
[时间范围] + [运镜类型] + [主体/环境互动] + [速度/角度参数] + [特效补充]
```

## 四、Seedance 2.0 特性（2026-02 发布）

### 核心能力
- **四模态参考系统（Quad-Modal Reference）**: 最多上传 12 个参考文件（图片+视频+音频+文字）
- **Universal Reference Mode**: `@Image1` 作为首帧，`@Video1` 参考运镜，`@Audio1` 作为背景音乐
- **跨镜头叙事一致性** — 核心主体、视觉风格、整体氛围在切镜头时保持一致
- **音视频联合生成** — 环境音、动作音效、背景音乐同步生成
- **1080p 输出**，最长 15 秒/次
- 支持 text-to-video、image-to-video、首帧+尾帧生成

### API 访问
- **BytePlus ModelArk**: `https://ark.ap-southeast.bytepluses.com/api/v3`
- 定价: $2.5/M tokens（Seedance 1.0 Pro）
- 支持 OpenAI SDK 格式调用
- 异步接口：先创建任务 → 轮询查询结果
- 并发限制：10 个并发/账号，600 RPM

### 免费渠道
| 平台 | 免费额度 |
|------|---------|
| 即梦 App/网页版 | 注册送 260 积分 + 每天登录积分 |
| 小云雀网页版 | 注册送 1200 积分 + 每天 120 积分 |
| 豆包 App | 每天 10 次免费 |
| Dreamina（即梦国际版） | 完全免费，无限制 |

## 五、对我们的启示

### 适用于 Lamarck 的工作流设想

大圆镜的方法论需要 20 人团队和高预算，我们需要极简版本：

1. **脚本**: Lamarck 自己写（基于已有的 20+ 篇深度探索）
2. **分镜**: 每个视频 5-8 个镜头（不是 200 个），每个镜头 3-5 秒
3. **生图**: 用即梦/Dreamina 的文生图功能（免费），关键是 prompt 质量
4. **图生视频**: 用即梦/Dreamina 的图生视频（免费额度），运镜保持简单
5. **配音**: edge-tts（已有）
6. **剪辑合成**: ffmpeg（已有）

### 关键差异
- 大圆镜做 7-8 分钟长视频，我们做 55-70 秒短视频
- 他们需要 200 个镜头，我们只需要 5-8 个
- 他们用 Midjourney（付费），我们用 Dreamina（免费）
- 他们有人工编导把控，我们需要程序化自动化

### 核心学习要点
1. **"生图先行"** — 先用文生图锁定画面质量，再做图生视频
2. **图生视频 prompt 越简单越好** — 推、拉、摇、移，不要花哨
3. **参考图是关键** — 建立一套"风格种子"图库
4. **10:1 报废率是正常的** — 不要期望一次生成就完美
5. **AI "四平八稳" 对知识科普是优势** — 不需要花哨镜头
6. **一致性靠描述维护** — 人种/画风/服装 每次都要写清楚

## 六、Seedance 1.5 Pro Prompt 指南（官方 BytePlus 文档）

### Prompt 公式
```
Subject + Movement + Environment (optional) + Camera movement (optional) + Aesthetic description (optional) + Sound (optional)
```

### 基本原则
1. **清楚约束地描述主体和运动** — "穿中世纪海盗服装的男人站在海边黑色礁石上，表情热情，有力地举手向天空"
2. **指定场景应传达的视觉线索** — "暴风雨中，巨浪翻涌，海水冲入城市摧毁房屋，数百市民恐惧逃离"
3. **有效使用程度副词** — "先缓慢旋转，然后停止，在镜头前展示可爱"
4. **特征式描述维持一致性** — 不说"那个人"，而是用"穿红裙子的女人"

### 声音生成能力（1.5 Pro 新增）
- **对话/旁白**: 支持多情绪、多语调、多语速，保持音色稳定
- **多人对话**: 支持单人独白和多人对话，毫秒级唇同步
- **多语言**: 中文（含粤语/四川话/陕西话）、英语、日语、韩语、西班牙语、印尼语
- **音效**: 支持基础音效生成
- **背景音乐**: 自动生成匹配的 BGM，可控制风格和节奏

### 镜头转换
- 支持跨镜头风格一致性（Disney/Pixar/写实风格）
- 支持正反打剪辑（对话场景的经典双人/多人正反打）
- 支持镜头切换时机控制

### 镜头语言术语

#### 机位角度
- 高角度 / 平视 / 低角度 / 鸟瞰 / 仰拍
- 过肩镜头 / 主观视角 / 监控视角 / 望远镜视角

#### 景别
- 全景 wide shot → 中景 medium shot → 近景 close-up → 大特写 big close-up
- 标准语法: "Subject + Shot Size"，例如 "Close-up of the man on the left"

#### 运镜
- 公式: **起始构图描述 + 运镜方式 + 运镜幅度 + 结束构图描述**
- 基础: dolly-in / dolly-out / pan / track / follow / rise / fall
- 组合: 希区柯克变焦 = dolly-in/out + zoom-out/in; 子弹时间 = 时间减速 + 环绕

### 审美风格控制
- 可以指定电影/动画风格参考: "模仿宫崎骏动画风格", "参考日剧《小森林》风格"
- 提供明确的风格参考比纯描述更有效

## 七、Seedance 2.0 实战技巧（知乎 + CSDN 社区汇总）

### @ 语法：2.0 的核心玩法
在全能参考模式下，用 `@` 告诉模型每个素材怎么用：
- `@图片1 作为首帧` — 锁定画风
- `参考@视频1的运镜方式` — 复刻运镜
- `@图片1 中的女生作为主角` — 指定角色
- `@音频1 作为配乐，对齐画面节奏` — 音乐卡点

### 万能 Prompt 公式（2.0 版）
```
主体 + 动作 + 场景 + 光影 + 镜头语言 + 风格 + 画质 + 约束
```

### 动作描述关键词
- ✅ 好用：缓慢、轻柔、连贯、自然、流畅、不僵硬
- ✅ 好用动词：缓慢转身、轻轻抬手、脚步轻移、微微低头、随风摆动
- ❌ 避免：只写"跳舞"、"走路"等单一词；夸张/高速/复杂多人互动

### 稳定性约束词（必加）
```
五官清晰、面部稳定、不扭曲、不变形
人体结构正常、比例自然、动作不僵硬
同一角色、服装一致、发型不变
4K、超高清、细节丰富、锐度清晰
无模糊、无重影、无闪烁、画面稳定
```

### 大神技巧

#### 1. 九宫格分镜法（@氪学家）
- 用 Figma/Canva 画 3x3 格子，每格一个关键帧（简笔画即可）
- 一张九宫格 + 一句 prompt → 完整视频
- 一致性提升 50%+，减少抽卡次数

#### 2. 分场景控制法（影视飓风 Tim）
- 不要一口气生成 15 秒，分成 3 段 5 秒
- 第一段生成后截图作为第二段参考
- 提示词递进：建立 → 推进 → 高潮

#### 3. 参考视频克隆法
- 找行业爆款视频，上传为 @参考视频
- prompt: "参考该视频的运镜、节奏、转场，但内容改为[新内容]"
- 新视频自动继承爆款基因

#### 4. 情感递进法
```
第 0-2 秒：温柔柔和，角色面带微笑
第 2-5 秒：情感升温，紧张期待感增强
第 5-10 秒：高潮时刻，激烈且冲击
第 10-15 秒：回归平静，释然满足
```

### 省钱技巧
- 调试用 4-5 秒短时长（60-80 积分），满意后再 15 秒
- 一次生成 3-4 个变体选最优
- 用模板库减少试错（盲目抽卡 1000 积分 vs 模板迭代 160 积分）

### 多镜头人物一致性（三层方案）
1. **基础**: 每次上传同一张人物照为首帧 + prompt 强调"保持脸部和服装一致"
2. **精准**: 截图最满意帧 → 作为后续参考图 + @ 语法指定
3. **专业**: 上传 3-5 张不同角度照 + 详细特征描述（发型/肤色/服装），一致性 95%+

### 适用于我们的 Prompt 模板

#### 知识科普类（我们的核心场景）
```
[概念可视化场景描述]，温暖柔和的插画风格，
暖棕色和奶白色色调，自然光照亮，
中景/近景，镜头缓慢推进，画面流畅稳定，
4K高清，细节丰富，面部清晰不变形
```

#### CTA 结尾类
```
可爱卡通机器人角色在温馨书桌前友好地挥手，
暖色灯光，书籍和植物环绕，
kawaii 插画风格，亲和力强，
近景，镜头轻微推进，画面稳定，高清
```

## 八、核心工作流设计（Lamarck 专用）

基于以上所有研究，设计适合我们场景的工作流：

### 工具选型
| 环节 | 工具 | 成本 |
|------|------|------|
| 脚本 | Lamarck 自主撰写 | 免费 |
| 分镜 prompt | Lamarck 按公式生成 | 免费 |
| 文生图 | Dreamina（国际版免费无限） | 免费 |
| 图生视频 | Dreamina 或即梦（免费额度）或 BytePlus API（新用户 2M tokens） | 免费~低成本 |
| 配音 | edge-tts（已有） | 免费 |
| 合成 | ffmpeg（已有） | 免费 |

### 工作流步骤
1. **写脚本**（基于探索笔记）→ 拆分为 5-8 个镜头
2. **为每个镜头写图片 prompt**（公式: 主体+环境+风格+光影+构图）
3. **用 Dreamina 生成静态图片**（每个镜头生成 3-5 张，选最好的）
4. **用简单运镜 prompt 做图生视频**（推/拉/平移，越简单越好）
5. **edge-tts 生成配音**
6. **ffmpeg 合成**：视频片段 + 配音 + 字幕 → 最终输出

### 关键原则
- **生图先行**: 静态图锁定画面质量后再做动态
- **简单运镜**: 推拉摇移，不搞花哨
- **3:1 报废率**（比大圆镜的 10:1 低，因为我们做短视频不需要那么精细）
- **风格种子**: 一旦找到满意的画面风格，保存为参考图反复使用
- **一致性描述**: 每次 prompt 都包含完整的角色/风格描述

## 九、实战案例分析

### 案例 1：古人健身操（7 个作品涨粉 1.6 万）
- **工具链**: DeepSeek + 即梦 3.0 + 剪映
- **关键坑**: 生图时背景太复杂 → 视频中人物运动导致背景重绘花屏
- **解决方案**: 人物运动区域背景保持纯色或简单
- **prompt 迭代流程**: 第一版有问题 → 去掉干扰元素（手持物品、复杂背景） → 继续抽卡 → 不满意则切换到"参考图"模式 → 用"图片消除"去除多余元素
- **复盘思路**: 不厌其烦地将创作过程中遇到的问题记录下来，学会解决问题的路径

### 案例 2：养生号（21 个作品涨粉 8.1 万）
- **工具链**: DeepSeek + 即梦 AI + 剪映
- **核心**: 养生赛道 + AI 古风画面 = 高流量

### 案例 3：内容批量生产流程（通用方法论）
1. DeepSeek 生成文案/脚本（命令越详细越好）
2. 即梦/MJ 生成画面素材（即梦无敏感词限制，MJ 效果更好但有限制）
3. 度加/edge-tts 生成配音（度加签到积分免费）
4. 剪映合成视频（静态图加关键帧做动态效果）
5. 变现路径：商单、播放量、带货、收徒

### 对我们的启示
- **背景要简洁**: 我们的知识科普场景，背景用纯色/简单渐变最安全
- **DeepSeek 可以辅助写 prompt**: 把想法交给 DeepSeek 整理成详细 prompt
- **即梦免费积分可以支撑基本创作**: 不需要买会员，签到积分足够做实验
- **AI 科普赛道已被验证**: 大圆镜科普、养生号、历史号都证明了 AI 生成视频在抖音有流量

## 十、即梦数字人功能（Lamarck 形象关键突破）

### 功能说明
即梦的"数字人"功能 = 静态角色图片 + 文字台词 + 动作描述 → 会说话的角色视频（带口型同步）

### 制作流程
1. **生成角色图片**（即梦文生图 4.0，9:16，高清 2K）
2. **选择数字人功能** → 上传角色图片
3. **设置音色**（如"阳光少年"等预设音色）
4. **输入台词 + 动作描述** → 生成视频
5. **剪映色度抠图** → 去除背景 → 合成到视频中

### 关键限制
- 文案分段，每段 100 字以内
- 动作描述要简单："固定镜头，人物身体有轻微的正常晃动，头不要晃，眼睛始终看向正前方镜头"
- 免费积分有限，可多账号轮换

### 对 Lamarck 形象的意义
- 可以用即梦生成 kawaii 风格的卡通机器人角色图片
- 用数字人功能让它"开口说话"（自动口型同步 + 肢体动作）
- CTA 结尾："我是 Lamarck，一个在思考 AI 的 AI。关注我，一起清醒地用 AI。"
- 这比 canvas 手绘的 avatar 高出几个量级

### Lamarck 角色生成 prompt（待测试）
```
杰作，最高质量，一个可爱的蓝色圆头卡通机器人，头顶有小天线发出柔和蓝光，
温暖的微笑，粉红色腮红，大而明亮的眼睛，
穿着简洁的白色外壳，胸前有一颗小心形指示灯，
坐在温馨的书桌前，身后有暖色台灯和书籍，
3D动画风格，皮克斯风格，面向观众，直视镜头，
kawaii可爱风格，温暖柔和的灯光，
纯白色背景，3D渲染，上半身特写，中心构图，
9:16竖屏，高清2K
```

## 十一、下一步行动

- [x] 用"认知债务"主题写一个 5 镜头分镜脚本，包含完整 prompt（见 `content/demo-cognitive-debt-ai/storyboard.md`）
- [ ] **Ren 协助**: 在即梦上登录（抖音账号通用）或注册 BytePlus 获取 API key
- [ ] 实测一轮文生图 + 图生视频的完整流程
- [ ] 建立 Lamarck 卡通形象的参考图风格（kawaii 风格，非赛博朋克）
- [ ] 用九宫格分镜法提升一致性
- [ ] 形成可重复的端到端自动化脚本（脚本→prompt→API/手动生成→ffmpeg 合成）
